{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacchunn/SC1015_MiniPrj_Airbnb/blob/main/Airbnb_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ1eg0w8LJ42"
      },
      "source": [
        "## Dataset : Airbnb Singapore Dataset from InsideAirbnb\n",
        "#### Question : If we were an AirBnb host, how can we maximise our profit?\n",
        "\n",
        "\n",
        "Dataset from Airbnb : **\"Singapore, 29 December 2022\"**  \n",
        "Source: http://insideairbnb.com/get-the-data/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnOQoO_E_iRe"
      },
      "source": [
        "# Contents\n",
        "  1. KMeans\n",
        "  2. Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Acgis14J_hvI"
      },
      "source": [
        "---\n",
        "\n",
        "### Essential Libraries\n",
        "\n",
        "Import essential libraries such as numpy, pandas, matplotlib and seaborn.\n",
        "\n",
        "> NumPy : Library for Numeric Computations in Python  \n",
        "> Pandas : Library for Data Acquisition and Preparation  \n",
        "> Matplotlib : Low-level library for Data Visualization  \n",
        "> Seaborn : Higher-level library for Data Visualization  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ACmnMeTUca-"
      },
      "outputs": [],
      "source": [
        "# Isaac Chun Jun Heng U2221389B\n",
        "# J'sen Ong Jia Xuan  U2220457J\n",
        "# Tang Teck Meng U2221809C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hL7LJWhgJrsN"
      },
      "outputs": [],
      "source": [
        "#Basic libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt #We only need pyplot\n",
        "sb.set() #Set the default Seaborn style for graphics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pDbWEh6L6sA"
      },
      "source": [
        "### Additional Libraries\n",
        "\n",
        "Import additional libraries\n",
        "\n",
        "> sklearn : Conduct linear regression analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxD0fh_dL-nM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP5VqEnbUnrw"
      },
      "source": [
        "### General Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXRLpW85UnSW"
      },
      "outputs": [],
      "source": [
        "def countOutliers (df):\n",
        "    #Get the q1 and q3 datas to find out the 25% and 75% range, then calculate inter quartile range and then find out whiskers.\n",
        "    #Then count how many points lie outside of this range.\n",
        "    q1 = df.quantile(0.25)\n",
        "    q3 = df.quantile(0.75)\n",
        "    #Interquartile\n",
        "    iqr = q3 - q1\n",
        "    #Calculate whiskers\n",
        "    leftWhisker = q1 - (1.5 * iqr)\n",
        "    rightWhisker = q3 + (1.5 * iqr)\n",
        "    outliers = 0;\n",
        "    #Loop through data now\n",
        "    for data in df:\n",
        "        if(data < leftWhisker or data > rightWhisker):\n",
        "            outliers+=1\n",
        "\n",
        "    return outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9_1xCppVW2a"
      },
      "outputs": [],
      "source": [
        "def removeOutliers(df, colName):\n",
        "  q1 = df[colName].quantile(0.25)\n",
        "  q3 = df[colName].quantile(0.75)\n",
        "  iqr = q3-q1\n",
        "  low = q1 - 1.5 * iqr\n",
        "  high = q3 + 1.5 * iqr\n",
        "  result = df.loc[(df[colName] >= low) & (df[colName] <= high)]\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3BFohdujXiY"
      },
      "outputs": [],
      "source": [
        "def remove_outliers(df, columns, factor=1.5):\n",
        "    # loop through each column and remove outliers based on the IQR method\n",
        "    for col in columns:\n",
        "        q1 = df[col].quantile(0.25)\n",
        "        q3 = df[col].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        upper_bound = q3 + factor * iqr\n",
        "        lower_bound = q1 - factor * iqr\n",
        "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcoll3Qzk1jo"
      },
      "source": [
        "### Mount Google Drive (unused, uncomment if need add anything from google drive.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDtEInVNk1DE"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive \n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJz4sgNK-9Rg"
      },
      "source": [
        "---\n",
        "\n",
        ">## Hypothesis  \n",
        "\n",
        "1. The number of amenities a listing provides will affect its price, the more the amenities, the higher the listing price\n",
        "2. Variables related to a listing's review will have positive correlation to listing's price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhcgD6G8qKqW"
      },
      "source": [
        "---\n",
        "\n",
        ">## Import the Dataset  \n",
        "\n",
        "We have imported the cleaned dataset based on our EDA done in the other files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUY3F6v5qM96"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/isaacchunn/SC1015_MiniPrj_Airbnb/main/listings_cleaned.csv\"\n",
        "airDF = pd.read_csv(url)\n",
        "airDF.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHp8igcBqL82"
      },
      "outputs": [],
      "source": [
        "airDF.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5MX-5B2qU8a"
      },
      "outputs": [],
      "source": [
        "print(airDF.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvcjlDhH9xYv"
      },
      "source": [
        "---\n",
        "\n",
        ">## Cleaning our DataFrame/Dataset\n",
        "\n",
        "### 1. Drop properties with N/A or 0% acceptance rate as these properties do not get stayed at by visitors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2pSGidJBTEJ"
      },
      "outputs": [],
      "source": [
        "#Drop all the properties that has no host acceptance rate then drop\n",
        "airDF = airDF.dropna(subset=[\"host_acceptance_rate\"])\n",
        "#Then remove all the 0% acceptance rate\n",
        "airDF = airDF[airDF[\"host_acceptance_rate\"] != 0]\n",
        "#Resort our indexes\n",
        "airDF = airDF.reset_index(drop=True)\n",
        "airDF.head(n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMl2vZu2dSoE"
      },
      "source": [
        "### 2. Clean the price column using code as it has \"$\", \",\" and \".\" \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giwEBBlOdbuY"
      },
      "outputs": [],
      "source": [
        "airDF[\"price\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kVBKlz1eE-b"
      },
      "outputs": [],
      "source": [
        "breaks = [\",\", \"$\"]\n",
        "for i in range(len(airDF[\"price\"])):\n",
        "    s = airDF.loc[:,(\"price\")][i]\n",
        "    for x in breaks:\n",
        "        s = s.replace(x,\"\")\n",
        "    s = \"\".join(s.split(\".\")[:-1])\n",
        "    airDF.loc[:,(\"price\")][i] = int(s)\n",
        "airDF = airDF.astype({'price': 'int32'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryQCXracarYN"
      },
      "source": [
        "We also remove any outliers as it is unrealistic for a property to have above > $45,000 per night"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa0ZTigjatzu"
      },
      "outputs": [],
      "source": [
        "airDF = airDF[airDF.price < 45000]\n",
        "#Resort our indexes\n",
        "airDF = airDF.reset_index(drop=True)\n",
        "airDF[\"price\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9UStzhsg3ib"
      },
      "source": [
        "### 3. Convert the amenities column to a list, and add a new column with the number of amenities to be used for our prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NfAXRWQgwEn"
      },
      "outputs": [],
      "source": [
        "airDF[\"amenities\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ho7aKHWh_kN"
      },
      "outputs": [],
      "source": [
        "#Add a new column of amenities\n",
        "airDF[\"no_amenities\"] = 0\n",
        "#Replace all with the integer variant\n",
        "count = 0\n",
        "for x in airDF[\"amenities\"]:   \n",
        "    #Convert string into list\n",
        "    #Convert string into list\n",
        "    x = x.replace('[',\"\")\n",
        "    x = x.replace(']',\"\")\n",
        "    x = x.replace('\"', \"\")\n",
        "    x = x.replace(\", \", \",\")\n",
        "    x = x.split(\",\")\n",
        "    airDF[\"amenities\"][count] = x\n",
        "    airDF[\"no_amenities\"][count] = len(x)\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhbl3Pf8JJri"
      },
      "outputs": [],
      "source": [
        "airDF[\"amenities\"].head(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlU3SR2TJJlE"
      },
      "outputs": [],
      "source": [
        "airDF[\"no_amenities\"].head(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJYiAqnfJfLl"
      },
      "outputs": [],
      "source": [
        "#Want to visualize the total count of amenities so we can form a generalization such that our number of amenities remains reliable.\n",
        "amenityCount = {}\n",
        "for x in airDF[\"amenities\"]:\n",
        "    for item in x:\n",
        "        if item in amenityCount:\n",
        "            amenityCount[item] += 1\n",
        "        else:\n",
        "            amenityCount[item] = 1\n",
        "        \n",
        "#Add it to a DF\n",
        "amenityCountDF = pd.DataFrame(columns = [\"amenity\", \"count\"])\n",
        "count = 0\n",
        "for keys, values in amenityCount.items():\n",
        "    amenityCountDF.loc[count] = [keys, values]\n",
        "    count += 1\n",
        "\n",
        "#Sort the DF\n",
        "amenityCountDF = amenityCountDF.sort_values(by=\"count\", ascending = False)\n",
        "amenityCountDF.head(n=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPd8kGnNJhzu"
      },
      "outputs": [],
      "source": [
        "amenityCountDF.tail(n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugII9aeyJjIF"
      },
      "source": [
        "We have decided to only use those amenities that are very prominent in most of the listings as the number of amenities should be consistent, and not be filled with many values that do not matter. For example, we do not know what Fire TV is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgBKIE1sJo9v"
      },
      "outputs": [],
      "source": [
        "#Changeable cutoff that are determined by us to check for robustness of our model\n",
        "amenityCutOff = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM8cjootJp2a"
      },
      "outputs": [],
      "source": [
        "uselessAmenityList = amenityCountDF[amenityCountDF[\"count\"] <= amenityCutOff][\"amenity\"].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyjUkunuJqp6"
      },
      "outputs": [],
      "source": [
        "#Remove all values in our df that correspond to our useless amenity list\n",
        "count = 0\n",
        "for x in airDF[\"amenities\"]:\n",
        "    l = [i for i in x if i not in uselessAmenityList]\n",
        "    airDF[\"amenities\"][count] = l\n",
        "    airDF[\"no_amenities\"][count] = len(l)\n",
        "    count +=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR7SXNKIvzMF"
      },
      "source": [
        "### 4. Fill in na values in host_response_time to be a value as we are using it to gather insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsiS8zKzv6gr"
      },
      "outputs": [],
      "source": [
        "print(\"Null values:\", airDF[\"host_response_time\"].isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKAY-XMhwBsP"
      },
      "outputs": [],
      "source": [
        "airDF[\"host_response_time\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8802nSSFwFdN"
      },
      "outputs": [],
      "source": [
        "#Fill it to be the worst scenario to achieve better distribution\n",
        "airDF = airDF.fillna(value = {\"host_response_time\": \"a few days or more\"})\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tD61eM8uwj_E"
      },
      "outputs": [],
      "source": [
        "print(\"Null values:\", airDF[\"host_response_time\"].isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YRfiStqwq5U"
      },
      "outputs": [],
      "source": [
        "airDF[\"host_response_time\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        ">## Splitting the Dataset"
      ],
      "metadata": {
        "id": "mQsqiqCSeAQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the dataset into train and test in 80:20 ratio\n",
        "train_data, test_data = train_test_split(airDF, test_size = 0.2, random_state = 55)\n",
        "\n",
        "#Print out what we have in our test and train data\n",
        "print(\"Train Data :\")\n",
        "print(\"Data type : \", type(train_data))\n",
        "print(\"Data dim : \", train_data.shape)\n",
        "print(\"---------------------------------------\")\n",
        "print(\"Test Data :\")\n",
        "print(\"Data type : \", type(test_data))\n",
        "print(\"Data dim : \", test_data.shape)\n",
        "print(\"---------------------------------------\")"
      ],
      "metadata": {
        "id": "mV0OCKPLeZZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        ">## 1. Multi-variate K Means"
      ],
      "metadata": {
        "id": "CCReoeXO-zLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "priceDF = airDF[\"price\"]\n",
        "priceDF.head(n=5)"
      ],
      "metadata": {
        "id": "erEEzZdosGoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input the numerical values we had identified beforehand\n",
        "kmeansDF = airDF[[\"accommodates\",\"no_amenities\",\"number_of_reviews\", \"price\",\"review_scores_rating\"]].copy()\n",
        "# filling in null values with median\n",
        "kmeansDF.fillna(kmeansDF.median(), inplace = True)\n",
        "\n",
        "#Plot its data on 2d grids\n",
        "sb.pairplot(kmeansDF)"
      ],
      "metadata": {
        "id": "TLzSXGjYfrW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import kmeans model from sklearn\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#Vary the number of clusters\n",
        "minClusterRange = 1\n",
        "maxClusterRange = 20\n",
        "\n",
        "#We want to use the elbow method, so we will compute all sse for each \"k\" and store into our sse list \n",
        "#\"k-means++\" employs an advanced trick to speed up convergence\n",
        "sse = [] \n",
        "for k in range(minClusterRange, maxClusterRange + 1):\n",
        "  kmeans = KMeans(n_clusters = k, init = \"k-means++\", n_init= 100)\n",
        "  kmeans.fit(kmeansDF)\n",
        "  sse.append(kmeans.inertia_)\n",
        "\n",
        "#Plot the SSE curve to find our elbow point\n",
        "f = plt.figure(figsize=(16,4))\n",
        "plt.plot(range(minClusterRange, maxClusterRange+1), sse)\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('SSE')\n",
        "plt.xticks(np.arange(minClusterRange, maxClusterRange+1, step = 1))\n",
        "plt.show()\n",
        "None"
      ],
      "metadata": {
        "id": "v9MuBOaZglg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems from this that our elbow point is either 2 or 3 as our best k. Let us use another technique called silhouette coefficient to find out the best k"
      ],
      "metadata": {
        "id": "dxDrW_dTojWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.cluster import silhouette_score\n",
        "silhouette_coefficients = []\n",
        "minClusterRange = 2 #Start at 2 for silhouette coefficient\n",
        "maxClusterRange = 20\n",
        "\n",
        "for k in range(minClusterRange, maxClusterRange +1):\n",
        "  kmeans = KMeans(n_clusters = k, init= \"k-means++\", n_init = 100)\n",
        "  kmeans.fit(kmeansDF)\n",
        "  score = silhouette_score(kmeansDF, kmeans.labels_)\n",
        "  silhouette_coefficients.append(score)"
      ],
      "metadata": {
        "id": "0PVEPxWlo8Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot out what we have found based on our silhouette coefficients\n",
        "plt.plot(range(minClusterRange, maxClusterRange + 1), silhouette_coefficients)\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"Silhouette Coefficient\")\n",
        "plt.xticks(np.arange(minClusterRange, maxClusterRange+1, step = 1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i2JsL7ewpdZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this, let us try 2 as it has the highest score for now"
      ],
      "metadata": {
        "id": "HvydrlLrqFpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 2\n",
        "\n",
        "#Use our kmeans with our newly found k\n",
        "kmeans = KMeans(n_clusters = k,         \n",
        "               init = \"k-means++\",\n",
        "               n_init = 100)                 \n",
        "\n",
        "#Fit the kmeans onto our DF\n",
        "kmeans.fit(kmeansDF)\n",
        "#Then call predict \n",
        "kmeansPrediction = kmeans.predict(kmeansDF)\n",
        "None"
      ],
      "metadata": {
        "id": "fPEeAahLhp09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_labeled = kmeansDF.copy()\n",
        "kmeans_labeled[\"Cluster\"] = pd.Categorical(kmeansPrediction)\n",
        "\n",
        "# Catplot the counts in our cluters\n",
        "sb.catplot(y = \"Cluster\", data = kmeans_labeled, kind = \"count\")"
      ],
      "metadata": {
        "id": "OBRZ_l9jiPlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot all our clusters on 2d grids using cluster column\n",
        "sb.pairplot(kmeans_labeled, vars = kmeansDF.columns.values, hue = \"Cluster\")"
      ],
      "metadata": {
        "id": "5v8u9NdaiYVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplots for all Features against the Clusters\n",
        "f, axes = plt.subplots(5, 1, figsize=(20,35))\n",
        "sb.boxplot(x = 'accommodates', y = 'Cluster', data = kmeans_labeled, ax = axes[0])\n",
        "sb.boxplot(x = 'no_amenities', y = 'Cluster', data = kmeans_labeled, ax = axes[1])\n",
        "sb.boxplot(x = 'number_of_reviews', y = 'Cluster', data = kmeans_labeled, ax = axes[2])\n",
        "sb.boxplot(x = 'price', y = 'Cluster', data = kmeans_labeled, ax = axes[3])\n",
        "sb.boxplot(x = 'review_scores_rating', y = 'Cluster', data = kmeans_labeled, ax = axes[4])"
      ],
      "metadata": {
        "id": "p2JrC7-_i8Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average Behaviour of each Cluster\n",
        "cluster_data = pd.DataFrame(kmeans_labeled.groupby(by = \"Cluster\").mean())\n",
        "cluster_data.plot.bar(figsize = (16,6))\n",
        "     "
      ],
      "metadata": {
        "id": "kH7IQ_6-jj8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data frame containing our centroids\n",
        "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=kmeansDF.columns)\n",
        "centroids['Cluster'] = centroids.index\n",
        "\n",
        "f, axes = plt.subplots(1, 1, figsize=(16,10))\n",
        "pd.plotting.parallel_coordinates(centroids, 'Cluster', color=('#556270', '#4ECDC4', '#C7F464'))"
      ],
      "metadata": {
        "id": "y8JQy9oCjs9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QcKktoS9j5Zc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Tcoll3Qzk1jo",
        "DhcgD6G8qKqW",
        "xvcjlDhH9xYv",
        "LMl2vZu2dSoE",
        "o9UStzhsg3ib",
        "TR7SXNKIvzMF"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "940f12be6d1e3c772de5e10a7b94e682f51674366be4bae6e0d292c730fd019e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}